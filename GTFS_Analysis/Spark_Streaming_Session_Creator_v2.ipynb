{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from sedona.spark import *\n",
    "from shapely import wkt\n",
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas as gpd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dd wkt csvs as geopandas geodataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinatown_df = pd.read_csv('Geofences/chinatown_wkt.csv')\n",
    "north_end_df = pd.read_csv('Geofences/Northend_wkt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinatown_df['geometry'] = chinatown_df['WKT'].apply(wkt.loads)\n",
    "north_end_df['geometry'] = north_end_df['WKT'].apply(wkt.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinatown_gdf = gpd.GeoDataFrame(chinatown_df, crs='EPSG:3857')\n",
    "north_end_gdf = gpd.GeoDataFrame(north_end_df, crs='EPSG:3857')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure sedona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SedonaContext.builder(). \\\n",
    "    config('spark.jars.packages',\n",
    "           'org.apache.sedona:sedona-spark-shaded-3.4_2.12:1.4.1,'\n",
    "           'org.datasyslab:geotools-wrapper:1.4.0-28.2'). \\\n",
    "    getOrCreate()\n",
    "sedona = SedonaContext.create(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "efine Spark streaming context and build app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "  .builder \\\n",
    "  .appName(\"Spark_Streaming_Session_Creator_v1.py\") \\\n",
    "  .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load kafka data into spark streaming session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_df = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "  .option(\"subscribe\", \"mbta-realtime\") \\\n",
    "  .load()\n",
    "stream_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ast json value as string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_df = stream_df.withColumn(\"value\", stream_df[\"value\"].cast(\"STRING\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "arse out lat and long information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude_expr = expr(\"get_json_object(value, '$.vehicle.position.latitude')\").alias(\"latitude\")\n",
    "longitude_expr = expr(\"get_json_object(value, '$.vehicle.position.longitude')\").alias(\"longitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new columns with lat and long information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_df = stream_df.withColumn(\"latitude\", latitude_expr).withColumn(\"longitude\", longitude_expr)\n",
    "parsed_df.printSchema()\n",
    "parsed_df.createOrReplaceTempView(\"parsed_json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "onvert the geometry to wkt and create spatial dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_df = sedona.sql(\"SELECT timestamp, st_point(longitude, latitude) AS geometry FROM parsed_json\")\n",
    "spatial_df.show(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tart the streaming query to process data in realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = spatial_df.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start() \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
